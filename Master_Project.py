# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lGhoOUdI9enMiT48qRALbWLMXXam-Gkt
"""

import os
import re
import json
import time
import subprocess
import shutil
from pathlib import Path
from typing import List, Optional

#  Paths

def get_repo_root() -> Path:
    return Path.cwd()

REPO = get_repo_root()
GRAMMAR_DIR = REPO / "grammar"
SANDBOX_DIR = REPO / "lean_sandbox"
ARTIFACTS_DIR = REPO / "artifacts"
DATASET_DIR = REPO / "dataset"
LOGS_DIR = REPO / "logs"
for d in (GRAMMAR_DIR, SANDBOX_DIR, ARTIFACTS_DIR, DATASET_DIR, LOGS_DIR):
    d.mkdir(parents=True, exist_ok=True)

LEMMA_SETS_PATH = GRAMMAR_DIR / "lemma_sets.json"
if not LEMMA_SETS_PATH.exists():
    LEMMA_SETS_PATH.write_text(json.dumps({
        "ADD": ["Nat.add_comm", "Nat.add_left_comm", "Nat.add_assoc", "Nat.zero_add", "Nat.add_zero"],
        "MUL": ["Nat.mul_comm", "Nat.mul_left_comm", "Nat.mul_assoc", "Nat.one_mul", "Nat.mul_one"],
        "ADD_MUL": [
            "Nat.add_comm","Nat.add_left_comm","Nat.add_assoc","Nat.zero_add","Nat.add_zero",
            "Nat.mul_comm","Nat.mul_left_comm","Nat.mul_assoc","Nat.one_mul","Nat.mul_one"
        ]
    }, indent=2), encoding="utf-8")

STEPS_TRAIN_PATH = DATASET_DIR / "steps_train.jsonl"
STEPS_VAL_PATH = DATASET_DIR / "steps_val.jsonl"
PRED_VAL_PATH = ARTIFACTS_DIR / "eval_predict_val.jsonl"
EVAL_FORMAL_VAL_PATH = ARTIFACTS_DIR / "eval_formal_val.jsonl"

# Lean checker

class LeanChecker:
    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.sandbox = repo_root / "lean_sandbox"
        self.lemma_sets_path = repo_root / "grammar" / "lemma_sets.json"
        self.lean_bin_path = self._find_lean_bin()

    def _find_lean_bin(self) -> str:
        p = os.environ.get("LEAN_BIN")
        if p and (Path(p).exists() or shutil.which(p)):
            return p
        p = shutil.which("lean")
        if p:
            return p
        p = str(Path.home() / ".elan" / "bin" / "lean")
        if Path(p).exists():
            return p
        raise RuntimeError("Lean binary not found. Set LEAN_BIN or add 'lean' to PATH.")

    def _expand_lemma_sets(self, tactic: str) -> str:
        if not self.lemma_sets_path.exists():
            return tactic
        lemma_sets = json.loads(self.lemma_sets_path.read_text(encoding="utf-8"))
        def repl(m):
            key = m.group(1)
            if key not in lemma_sets:
                raise ValueError(f"Unknown lemma set: {key}")
            return "[" + ", ".join(lemma_sets[key]) + "]"
        return re.sub(r"\[\s*(ADD|MUL|ADD_MUL)\s*\]", repl, tactic)

    def _render_source(self, name: str, params: str, goal: str, tactic_lines: List[str]) -> str:
        out = [
            "set_option linter.unusedVariables false",
            "",
            f"theorem {name} {params.strip()} : {goal.strip()} := by",
        ]
        for t in tactic_lines:
            out.append("  " + self._expand_lemma_sets(t.strip()))
        out.append("")
        return "\n".join(out)

    def verify_proof(self, statement: dict, tactics: List[str], timeout_s: int = 20) -> dict:
        src = self._render_source(
            name=statement["name"],
            params=statement.get("params", ""),
            goal=statement["goal"],
            tactic_lines=tactics,
        )
        self.sandbox.mkdir(parents=True, exist_ok=True)
        src_path = self.sandbox / "Sandbox.lean"
        src_path.write_text(src, encoding="utf-8")
        t0 = time.time()
        try:
            proc = subprocess.run(
                [self.lean_bin_path, str(src_path)],
                cwd=str(self.sandbox),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=timeout_s,
            )
            return {
                "name": statement["name"],
                "success": proc.returncode == 0,
                "time_s": time.time() - t0,
                "stderr_tail": proc.stderr[-300:]
            }
        except subprocess.TimeoutExpired:
            return {"name": statement["name"], "success": False, "time_s": timeout_s, "stderr_tail": "timeout_expired"}
        except Exception as e:
            return {"name": statement["name"], "success": False, "time_s": 0, "stderr_tail": str(e)}

#  Parsing

def parse_input_text(s: str):
    m1 = re.search(r"Params:\s*(.+)\n", s)
    m2 = re.search(r"Goal:\s*(.+)$", s, flags=re.S)
    params = m1.group(1).strip() if m1 else ""
    goal = m2.group(1).strip() if m2 else ""
    return params, goal

#  Minimal model placeholders

class DummyModel:
    def train(self): ...
    def eval(self): ...
    def __call__(self, env, local_context, goal, tactic_actions, use_teacher_forcing):
        loss = 0.1
        predicted = []
        for a in tactic_actions:
            acts = a.get("actions", [])
            if "RflCall->rfl" in acts:
                predicted.append(SimpleAST("rfl"))
            elif "SimpAllCall->simp_all" in acts:
                predicted.append(SimpleAST("simp_all"))
            elif "SimpCall->simp[Set]" in acts:
                ls = next((x.split("->",1)[1] for x in acts if x.startswith("LemmaSet->")), "ADD")
                predicted.append(SimpleAST(f"simp [{ls}]"))
            elif "RwCall->rw[Set]" in acts:
                ls = next((x.split("->",1)[1] for x in acts if x.startswith("LemmaSet->")), "ADD")
                predicted.append(SimpleAST(f"rw [{ls}]"))
            elif "ExactCall->exact Lemma" in acts:
                nm = next((x.split("->",1)[1] for x in acts if x.startswith("LemmaName->")), "Nat.add_comm")
                predicted.append(SimpleAST(f"exact {nm}"))
            elif "ApplyCall->apply Lemma" in acts:
                nm = next((x.split("->",1)[1] for x in acts if x.startswith("LemmaName->")), "Nat.add_comm")
                predicted.append(SimpleAST(f"apply {nm}"))
            else:
                predicted.append(SimpleAST("simp"))
        return predicted, DummyLoss(loss)

class DummyLoss:
    def __init__(self, v: float): self.v = v
    def item(self): return self.v

class SimpleAST:
    def __init__(self, s: str): self.s = s
    def to_tokens(self): return self.s

class ProgressBar:
    def __init__(self, total: int): self.total = total
    def update(self, i: int):
        if self.total and (i % max(1, self.total // 10) == 0):
            print(f"progress {i}/{self.total}")

class Agent:
    def __init__(self, model, dataloader, teacher_forcing: float = 0.0):
        self.model = model
        self.dataloader = dataloader
        self.teacher_forcing = teacher_forcing

    def train(self, n_epoch: int):
        self.model.train()
        bar = ProgressBar(len(self.dataloader["train"]))
        for i, batch in enumerate(self.dataloader["train"]):
            self.model(
                batch["env"], batch["local_context"], batch["goal"], batch["tactic_actions"],
                use_teacher_forcing=False
            )
            bar.update(i)

    def evaluate(self, out_path: Path):
        self.model.eval()
        preds = []
        correct = 0
        bar = ProgressBar(len(self.dataloader["val"]))
        for i, batch in enumerate(self.dataloader["val"]):
            asts, loss = self.model(
                batch["env"], batch["local_context"], batch["goal"], batch["tactic_actions"], False
            )
            for n in range(len(batch["file"])):
                tac_gt = batch["tactic_str"][n]
                tac_pred = asts[n].to_tokens()
                if tac_gt.replace(" ", "") == tac_pred.replace(" ", ""):
                    correct += 1
                preds.append({
                    "file_name": batch["file"][n],
                    "proof_name": batch["proof_name"][n],
                    "n_step": batch["n_step"][n],
                    "tac_gt": tac_gt,
                    "tac_pred": tac_pred,
                    "input_text": batch["input_text"][n],
                })
            bar.update(i)
        with out_path.open("w", encoding="utf-8") as f:
            for r in preds:
                f.write(json.dumps(r, ensure_ascii=False) + "\n")
        return preds, correct

#  Data layer

class DummyLoader:
    def __init__(self, size=100):
        self.size = size
    def __len__(self): return self.size
    def __iter__(self):
        for i in range(self.size):
            yield {
                "env": {},
                "local_context": [],
                "goal": {},
                "tactic_actions": [{'actions': ['Tactic->RflCall', 'RflCall->rfl']}],
                "file": [f"file_{i}.lean"],
                "proof_name": [f"thm_{i}"],
                "n_step": [0],
                "tactic_str": ["rfl"],
                "input_text": ["Params: (a : Nat)\nGoal: a = a"]
            }

def build_dataloader():
    return {"train": DummyLoader(size=200), "val": DummyLoader(size=55)}

#  Baseline tactic

def baseline_tactic(goal_text: str) -> str:
    has_add = ("+" in goal_text)
    has_mul = ("*" in goal_text)
    if has_add and has_mul: return "simp [ADD_MUL]"
    if has_add: return "simp [ADD]"
    if has_mul: return "simp [MUL]"
    return "simp"

#  Main

def main():
    dataloader = build_dataloader()
    model = DummyModel()
    agent = Agent(model, dataloader, teacher_forcing=0.0)
    checker = LeanChecker(REPO)

    print("training…")
    agent.train(n_epoch=1)

    print("predicting…")
    predictions, _ = agent.evaluate(PRED_VAL_PATH)
    print(f"saved predictions: {PRED_VAL_PATH}")

    print("formal verification…")
    num_ok = 0
    t0 = time.time()
    with EVAL_FORMAL_VAL_PATH.open("w", encoding="utf-8") as fout:
        for rec in predictions:
            params, goal = parse_input_text(rec["input_text"])
            tac_pred = rec["tac_pred"] or baseline_tactic(goal)
            stmt = {"name": f"Thm_{rec['proof_name']}", "params": params, "goal": goal}
            res = checker.verify_proof(stmt, [tac_pred], timeout_s=25)
            ok = bool(res["success"])
            if ok:
                num_ok += 1
            fout.write(json.dumps({
                "name": rec["proof_name"],
                "params": params,
                "goal": goal,
                "tac_pred": tac_pred,
                "verified": ok
            }, ensure_ascii=False) + "\n")
    elapsed = time.time() - t0
    total = len(predictions)
    rate = num_ok / total if total else 0.0
    print(f"Evaluated {total} | Formally-correct {num_ok} ({rate:.2%}) | time={elapsed:.1f}s")
    print(f"saved: {EVAL_FORMAL_VAL_PATH}")

if __name__ == "__main__":
    main()